type: sft
micro_batch_size: 2
epochs: 1
gradient_accumulation_steps: 1
model:
  type: liger
  name_or_path: meta-llama/Meta-Llama-3.1-8B
tokenizer:
  name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
data:
  sources:
    - HuggingFaceH4/ultrachat_200k
  use_data_cache: true
  cache_processed_data: true
  cache_dir: /data-fast/st-data-redesign
  num_proc: 16
logger:
  output_dir: "./"
  file_output_ranks: [0]
scheduler:
  lr: 1e-5
checkpoint:
  - type: deepspeed
    save_every_n_steps: 1000
    output_dir: /data-fast/checkpoint-redesign
