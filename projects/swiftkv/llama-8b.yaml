type: swiftkv
micro_batch_size: 1
epochs: 1
gradient_accumulation_steps: 1
temperature: 2.0
decoder_loss_mult: 0.0
model:
  name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
  num_key_value_layers: 16
  key_value_group_size: 1
deepspeed:
  zero_optimization:
    stage: 2
    memory_efficient_linear: false
data:
  sources:
    - HuggingFaceH4/ultrachat_200k
    - meta-math/MetaMathQA
    - ise-uiuc/Magicoder-OSS-Instruct-75K
    - lmsys/lmsys-chat-1m
    - Open-Orca/SlimOrca
  use_data_cache: true
  cache_processed_data: true
  cache_dir: /data-fast/st-data-redesign
  num_proc: 16
  max_length: 8192
logger:
  output_dir: "./"
  file_output_ranks: [0]
scheduler:
  lr: 0.0002
  warmup_ratio: 0.05
optimizer:
  betas: [0.9,0.999]
  weight_decay: 0.0
checkpoint:
  - type: deepspeed
    save_every_n_steps: 1000
    output_dir: /data-fast/checkpoint-redesign
